# awesome-chinese-ner
中文命名实体识别

#### 延申
- 中文预训练模型综述 <br>
https://www.jsjkx.com/CN/10.11896/jsjkx.211200018
- 中文预训练模型下载地址<br>
https://github.com/lonePatient/awesome-pretrained-chinese-nlp-models
- 中文词向量下载地址<br>
https://github.com/Embedding/Chinese-Word-Vectors
- Bilstm_CRF怎么调参？ <br>
https://arxiv.org/pdf/1707.06799.pdf
- 使用chatgpt进行信息抽取（实体、关系、事件）<br>
Zero-Shot Information Extraction via Chatting with ChatGPT<br>
演示地址：http://124.221.16.143:5000/<br>
https://arxiv.org/pdf/2302.10205.pdf<br>
https://github.com/cocacola-lab/ChatIE<br>
- GPT for Information Extraction<br>
https://github.com/cocacola-lab/GPT4IE<br>
- Evaluation-of-ChatGPT-on-Information-Extraction<br>
https://github.com/RidongHan/Evaluation-of-ChatGPT-on-Information-Extraction<br>
- 这篇把它放在延申这里：<br>
Unified Text Structuralization with Instruction-tuned Language Models<br>
2023<br>
https://arxiv.org/pdf/2303.14956v2.pdf<br>
- GPT-NER: Named Entity Recognition via Large Language Models<br>
2023<br>
https://arxiv.org/pdf/2304.10428v1.pdf<br>
https://github.com/ShuheWang1998/GPT-NER<br>
- EasyInstruct: An Easy-to-use Framework to Instruct Large Language Models<br>
https://github.com/zjunlp/EasyInstruct
- CODEIE: Large Code Generation Models are Better Few-Shot Information Extractors<br>
在代码中进行实体和关系的提取<br>
2023<br>
https://arxiv.org/pdf/2305.05711v1.pdf<br>
https://github.com/dasepli/CodeIE<br>


#### 命名实体识别综述（中文）
- 基于深度学习的中文命名实体识别最新研究进展综述<br>
2022年 中文信息学报<br>
http://61.175.198.136:8083/rwt/125/http/GEZC6MJZFZZUPLSSGM3B/Qikan/Article/Detail?id=7107633068<br>
- 命名实体识别方法研究综述<br>
2022年 计算机科学与探索<br>
http://fcst.ceaj.org/CN/10.3778/j.issn.1673-9418.2112109<br>
- 中文命名实体识别综述<br>
2021年 计算机科学与探索<br>
http://fcst.ceaj.org/CN/abstract/abstract2902.shtml<br>
- Chinese named entity recognition: The state of the art<br>
Neurocomputing 2022<br>
[link](https://reader.elsevier.com/reader/sd/pii/S0925231221016581?token=592CD98CF076A91AFE5EDB2396D806784B30D3217FD7B61FE2FE9CB905451ABB5B28C0285AAFA973010ACE14AD387A5C&originRegion=us-east-1&originCreation=20221119143715) 

# 模型
- Attack Named Entity Recognition by Entity Boundary Interference<br>
2023<br>
https://arxiv.org/pdf/2305.05253v1.pdf<br>
- Token Relation Aware Chinese Named Entity Recognition<br>
ACM Transactions on Asian and Low-Resource Language Information Processing 2023<br>
https://dl.acm.org/doi/10.1145/3531534<br>
- PUnifiedNER: a Prompting-based Unified NER System for Diverse Datasets<br>
AAAI 2023<br>
https://arxiv.org/pdf/2211.14838.pdf<br>
https://github.com/GeorgeLuImmortal/PUnifiedNER<br>
- END-TO-END ENTITY DETECTION WITH PROPOSER ANDREGRESSOR<br>
借鉴目标检测的思想<br>
2022<br>
https://arxiv.org/pdf/2210.10260v2.pdf<br>
https://github.com/Rosenberg37/EntityDetection<br>
- DAMO-NLP at SemEval-2022 Task 11:A Knowledge-based System for Multilingual Named Entity Recognition<br>
多语言的命名实体识别<br>
2022<br>
https://arxiv.org/pdf/2203.00545.pdf<br>
https://github.com/Alibaba-NLP/KB-NER<br>
- PCBERT: Parent and Child BERT for Chinese Few-shot NER<br>
COLING 2022<br>
https://aclanthology.org/2022.coling-1.192.pdf
- GNN-SL: Sequence Labeling Based on Nearest Examples via GNN<br>
2022<br>
https://arxiv.org/pdf/2212.02017.pdf<br>
https://github.com/ShuheWang1998/GNN-SL
- EiCi: A New Method of Dynamic Embedding Incorporating Contextual Information in Chinese NER<br>
这个和AMBERT的思想感觉差不多：[AMBERT](https://arxiv.org/pdf/2008.11869.pdf)<br>
2022<br>
https://openreview.net/pdf?id=0TKg4UlnEEQ
- Deep Span Representations for Named Entity Recognition<br>
2022<br>
https://arxiv.org/pdf/2210.04182v1.pdf
- Mulco: Recognizing Chinese Nested Named Entities Through Multiple Scopes<br>
2022<br>
https://arxiv.org/pdf/2211.10854.pdf
- Unsupervised Boundary-Aware Language Model Pretraining for Chinese Sequence Labeling<br>
EMNLP 2022<br>
https://arxiv.org/pdf/2210.15231.pdf<br>
http://github.com/modelscope/adaseq/examples/babert
- Domain-Specific NER via Retrieving Correlated Samples<br>
COLING 2022<br>
https://arxiv.org/pdf/2208.12995.pdf
- Two Languages Are Better than One: Bilingual Enhancement for Chinese Named Entity Recognition<br>
COLING 2022<br>
https://aclanthology.org/2022.coling-1.176.pdf
- A hybrid Transformer approach for Chinese NER with features augmentation<br>
Expert Syst. Appl 2022<br>
https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4087645
- Adaptive Threshold Selective Self-Attention for Chinese NER<br>
COLING 2022<br>
https://aclanthology.org/2022.coling-1.157.pdf
- Improving Chinese Named Entity Recognition by Search Engine Augmentation<br>
2022<br>
https://arxiv.org/pdf/2210.12662.pdf<br>
- Domain-Specific NER via Retrieving Correlated Samples<br>
COLING 2022<br>
https://arxiv.org/pdf/2208.12995.pdf<br>
- Robust Self-Augmentation for Named Entity Recognition with Meta Reweighting<br>
NAACL 2022 <br>
https://arxiv.org/pdf/2204.11406.pdf<br>
https://github.com/LindgeW/MetaAug4NER<br>
- Boundary Smoothing for Named Entity Recognition<br>
ACL 2022<br>
https://arxiv.org/pdf/2204.12031v1.pdf<br>
https://github.com/syuoni/eznlp<br>
- NFLAT: Non-Flat-Lattice Transformer for Chinese Named Entity Recognition <br>
2022 <br>
https://arxiv.org/pdf/2205.05832.pdf <br>
- Unified Structure Generation for Universal Information Extraction <br>
（一统实体识别、关系抽取、事件抽取、情感分析），百度UIE<br>
ACL 2022 <br>
https://arxiv.org/pdf/2203.12277.pdf <br>
https://github.com/PaddlePaddle/PaddleNLP/tree/develop/model_zoo/uie <br>
https://github.com/universal-ie/UIE <br>
以下这篇也是通用的，只是英文方面的，没有中文数据上的实验：
  - DEEPSTRUCT: Pretraining of Language Models for Structure Prediction <br>
  2022<br>
  https://arxiv.org/pdf/2205.10475v1.pdf<br>
  https://github.com/cgraywang/deepstruct<br>

- Parallel Instance Query Network for Named Entity Recognition <br>
2022 <br>
https://arxiv.org/pdf/2203.10545v1.pdf <br>
- Delving Deep into Regularity: A Simple but Effective Method for Chinese Named Entity Recognition<br>
NAACL 2022<br>
https://arxiv.org/pdf/2204.05544.pdf<br>
- TURNER: The Uncertainty-based Retrieval Framework for Chinese NER<br>
2022<br>
https://arxiv.org/pdf/2202.09022 <br>
- NN-NER: Named Entity Recognition with Nearest Neighbor Search<br>
2022 <br>
https://arxiv.org/pdf/2203.17103<br>
https://github.com/ShannonAI/KNN-NER<br>
- Unified Named Entity Recognition as Word-Word Relation Classification<br>
AAAI 2022 <br>
https://arxiv.org/abs/2112.10070 <br>
https://github.com/ljynlp/W2NER.git<br>
- MarkBERT: Marking Word Boundaries Improves Chinese BERT<br>
2022 <br>
https://arxiv.org/pdf/2203.06378<br>
- MFE-NER: Multi-feature Fusion Embedding for Chinese Named Entity Recognition<br>
2021 <br>
https://arxiv.org/pdf/2109.07877<br>
- AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with Incomplete Annotations<br>
2021 <br>
https://arxiv.org/pdf/2109.05233<br>
- ChineseBERT: Chinese Pretraining Enhanced by Glyph and Pinyin Information <br>
ACL 2021<br>
https://arxiv.org/pdf/2106.16038<br>
https://github.com/ShannonAI/ChineseBert<br>
- Enhanced Language Representation with Label Knowledge for Span Extraction<br>
EMNLP 2021<br>
https://aclanthology.org/2021.emnlp-main.379.pdf<br>
https://github.com/Akeepers/LEAR <br>
- Lex-BERT: Enhancing BERT based NER with lexicons  <br>
ICLR 2021 <br>
https://arxiv.org/pdf/2101.00396v1.pdf<br>
- Lexicon Enhanced Chinese Sequence Labeling Using BERT Adapter <br>
ACL 2021 <br>
https://arxiv.org/pdf/2105.07148.pdf<br>
https://github.com/liuwei1206/LEBERT<br>
- MECT: Multi-Metadata Embedding based Cross-Transformer for Chinese Named Entity Recognition  <br>
ACL 2021  <br>
https://arxiv.org/pdf/2107.05418v1.pdf<br>
https://github.com/CoderMusou/MECT4CNER <br>
- Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition <br>
ACL 2021   <br>
https://arxiv.org/pdf/2105.06804v2.pdf<br>
https://github.com/tricktreat/locate-and-label <br>
- Dynamic Modeling Cross- and Self-Lattice Attention Network for Chinese NER<br>
AAAI 2021<br>
https://ojs.aaai.org/index.php/AAAI/article/view/17706/17513<br>
https://github.com/zs50910/DCSAN-for-Chinese-NER<br>
- Improving Named Entity Recognition with Attentive Ensemble of Syntactic Information  <br>
EMNLP-2020 <br>
https://arxiv.org/pdf/2010.15466  <br>
https://github.com/cuhksz-nlp/AESINER <br>
- ZEN: Pre-training Chinese Text Encoder Enhanced by N-gram Representations  <br>
ACL 2020  <br>
https://arxiv.org/pdf/1911.00720v1.pdf<br>
https://github.com/sinovation/ZEN <br>
- A Unified MRC Framework for Named Entity Recognition  <br>
ACL 2020  <br>
https://arxiv.org/pdf/1910.11476v6.pdf<br>
https://github.com/ShannonAI/mrc-for-flat-nested-ner <br>
- Simplify the Usage of Lexicon in Chinese NER  <br>
ACL 2020   <br>
https://arxiv.org/pdf/1908.05969.pdf<br>
https://github.com/v-mipeng/LexiconAugmentedNER <br>
- A Boundary Regression Model for Nested Named Entity Recognition<br>
2020<br>
https://arxiv.org/pdf/2011.14330v3.pdf<br>
https://github.com/yuelfei/BR<br>
- Dice Loss for Data-imbalanced NLP Tasks  <br>
ACL 2020  <br>
https://arxiv.org/pdf/1911.02855v3.pdf<br>
https://github.com/ShannonAI/dice_loss_for_NLP <br>
- Porous Lattice Transformer Encoder for Chinese NER<br>
COLING 2020<br>
https://aclanthology.org/2020.coling-main.340.pdf<br>
- FLAT: Chinese NER Using Flat-Lattice Transformer  <br>
ACL 2020  <br>
https://arxiv.org/pdf/2004.11795v2.pdf<br>
https://github.com/LeeSureman/Flat-Lattice-Transformer <br>
- FGN: Fusion Glyph Network for Chinese Named Entity Recognition  <br>
2020  <br>
https://arxiv.org/pdf/2001.05272v6.pdf  <br>
https://github.com/AidenHuen/FGN-NER<br>
- SLK-NER: Exploiting Second-order Lexicon Knowledge for Chinese NER <br>
2020 <br>
https://arxiv.org/pdf/2007.08416v1.pdf<br>
https://github.com/zerohd4869/SLK-NER <br>
- Entity Enhanced BERT Pre-training for Chinese NER<br>
EMNLP 2020<br>
https://aclanthology.org/2020.emnlp-main.518.pdf<br>
https://github.com/jiachenwestlake/Entity_BERT<br>
- Improving Named Entity Recognition with Attentive Ensemble of Syntactic Information  <br>
ACL2020 <br>
https://arxiv.org/pdf/2010.15466v1.pdf<br>
https://github.com/cuhksz-nlp/AESINER  <br>
- Named Entity Recognition for Social Media Texts with Semantic Augmentation  <br>
EMNLP 2020  <br>
https://arxiv.org/pdf/2010.15458v1.pdf<br>
https://github.com/cuhksz-nlp/SANER <br>
- CLUENER2020: Fine-grained Named Entity Recognition Dataset and Benchmark for Chinese  <br>
2020  <br>
https://arxiv.org/pdf/2001.04351v4.pdf<br>
https://github.com/CLUEbenchmark/CLUENER2020 <br>
- ERNIE: Enhanced Representation through Knowledge Integration  <br>
2019  <br>
https://arxiv.org/pdf/1904.09223v1.pdf<br>
https://github.com/PaddlePaddle/ERNIE <br>
- TENER: Adapting Transformer Encoder for Named Entity Recognition  <br>
2019  <br>
https://arxiv.org/pdf/1911.04474v3.pdf<br>
https://github.com/fastnlp/TENER <br>
- Chinese NER Using Lattice LSTM  <br>
ACL 2018  <br>
https://arxiv.org/pdf/1805.02023v4.pdf<br>
https://github.com/jiesutd/LatticeLSTM <br>
- ERNIE 2.0: A Continual Pre-training Framework for Language Understanding  <br>
2019  <br>
https://arxiv.org/pdf/1907.12412v2.pdf<br>
https://github.com/PaddlePaddle/ERNIE <br>
- Glyce: Glyph-vectors for Chinese Character Representations  <br>
NeurIPS 2019  <br>
https://arxiv.org/pdf/1901.10125v5.pdf<br>
https://github.com/ShannonAI/glyce <br>
- CAN-NER: Convolutional Attention Network for Chinese Named Entity Recognition   <br>
NAACL 2019   <br>
https://arxiv.org/pdf/1904.02141v3.pdf<br>
https://github.com/microsoft/vert-papers/tree/master/papers/CAN-NER<br>
- Neural Chinese Named Entity Recognition via CNN-LSTM-CRF and Joint Training with Word Segmentation  <br>
2019  <br>
https://arxiv.org/pdf/1905.01964v1.pdf<br>
https://github.com/rxy007/cnn-lstm-crf <br>
- Chinese Named Entity Recognition Augmented with Lexicon Memory  <br>
2019  <br>
https://arxiv.org/pdf/1912.08282v2.pdf<br>
https://github.com/dugu9sword/LEMON <br>
- Exploiting Multiple Embeddings for Chinese Named Entity Recognition   <br>
2019  <br>
https://arxiv.org/pdf/1908.10657v1.pdf<br>
https://github.com/WHUIR/ME-CNER <br>
- Dependency-Guided LSTM-CRF for Named Entity Recognition <br>
IJCNLP 2019  <br>
https://arxiv.org/pdf/1909.10148v1.pdf<br>
https://github.com/allanj/ner_with_dependency <br>
- CAN-NER: Convolutional Attention Network for Chinese Named Entity Recognition <br>
NAACL-HLT (1) 2019 <br>
https://aclanthology.org/N19-1342/ <br>
- CNN-Based Chinese NER with Lexicon Rethinking <br>
IJCAI 2019 <br>
https://www.ijcai.org/proceedings/2019/0692.pdf <br>
https://aclanthology.org/N19-1342.pdf <br>
- Leverage Lexical Knowledge for Chinese Named Entity Recognition via Collaborative Graph Network <br>
IJCNLP 2019  <br>
https://aclanthology.org/D19-1396.pdf<br>
https://github.com/DianboWork/Graph4CNER <br>
- Distantly Supervised NER with Partial Annotation Learning and Reinforcement Learning  <br>
COLING 2018   <br>
https://aclanthology.org/C18-1183.pdf<br>
https://github.com/rainarch/DSNER <br>
- Adversarial Transfer Learning for Chinese Named Entity Recognition with Self-Attention Mechanism  <br>
EMNLP 2018  <br>
https://aclanthology.org/D18-1017.pdf<br>
https://github.com/CPF-NLPR/AT4ChineseNER <br>

# 非中文模型

没有针对于中文的实验，但是思想可以借鉴的： <br>
- DiffusionNER: Boundary Diffusion for Named Entity Recognition<br>
2023<br>
https://arxiv.org/pdf/2305.13298v1.pdf<br>
https://github.com/tricktreat/DiffusionNER<br>
- Learning In-context Learning for Named Entity Recognition<br>
ACL 2023<br>
https://arxiv.org/pdf/2305.11038v1.pdf<br>
https://github.com/chen700564/metaner-icl<br>
- UniEX: An Effective and Efficient Framework for Unified Information Extraction via a Span-extractive Perspective<br>
2023<br>
https://arxiv.org/pdf/2305.10306v1.pdf<br>
- Easy-to-Hard Learning for Information Extraction∗ <br>
2023 <br>
https://arxiv.org/pdf/2305.09193v1.pdf <br>
https://github.com/DAMO-NLP-SG/IE-E2H <br>
- UTC-IE: A Unified Token-pair Classification Architecture for Information Extraction<br>
2023<br>
https://openreview.net/pdf?id=cRQwl-59CU8<br>
https://github.com/yhcc/utcie<br>
- Deep Span Representations for Named Entity Recognition<br>
Boundary Smoothing for Named Entity Recognition(同作者)<br>
ACL 2023<br>
https://github.com/syuoni/eznlp<br>
https://arxiv.org/pdf/2210.04182v2.pdf<br>
- NER-to-MRC: Named-Entity Recognition Completely Solving as Machine Reading Comprehension<br>
2023<br>
https://arxiv.org/pdf/2305.03970v1.pdf<br>
- RexUIE: A Recursive Method with Explicit Schema Instructor for Universal Information Extraction<br>
通用信息抽取，对比USM<br>
2023<br>
https://arxiv.org/pdf/2304.14770.pdf<br>
- InstructUIE: Multi-task Instruction Tuning for Unified Information Extraction<br>
（又一篇通用信息抽取，对比百度UIE以及USM）<br>
2023<br>
https://arxiv.org/pdf/2304.08085v1.pdf<br>
https://github.com/BeyonderXX/InstructUIE<br>
- Universal Information Extraction as Unified Semantic Matching<br>
通用的信息抽取：实体、关系、事件（没有在中文数据上的实验），简称USM<br>
AAAI 2023<br>
https://arxiv.org/pdf/2301.03282.pdf<br>
- MULTI-TASK TRANSFORMER WITH RELATION-ATTENTION AND TYPE-ATTENTION FOR NAMED ENTITY RECOGNITION<br>
2023<br>
https://arxiv.org/pdf/2303.10870v1.pdf<br>
- DEEPSTRUCT: Pretraining of Language Models for Structure Prediction<br>
通用信息抽取<br>
ACL 2022<br>
https://arxiv.org/pdf/2205.10475v2.pdf<br>
https://github.com/cgraywang/deepstruct<br>
- TOE: A Grid-Tagging Discontinuous NER Model Enhanced by Embedding Tag/Word Relations and More Fine-Grained Tags<br>
改进W2NER模型<br>
IEEE TASLP(Transactions on Audio, Speech and Language Processing)<br>
https://arxiv.org/pdf/2211.00684.pdf<br>
https://github.com/solkx/TOE<br>
- OPTIMIZING BI-ENCODER FOR NAMED ENTITY RECOGNITION VIA CONTRASTIVE LEARNING<br>
ICLR 2023<br>
https://arxiv.org/pdf/2208.14565v2.pdf<br>
github.com/microsoft/binder<br>
- One Model for All Domains: Collaborative Domain-Prefix Tuning for Cross-Domain NER<br>
2023<br>
https://arxiv.org/pdf/2301.10410v2.pdf<br>
https://github.com/zjunlp/DeepKE/tree/main/example/ner/cross<br>
- QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition<br>
2022<br>
https://arxiv.org/pdf/2203.01543.pdf<br>
- A Unified Generative Framework for Various NER Subtasks <br>
（使用BART生成模型进行命名实体识别） <br>
ACL-ICJNLP 2021 <br>
https://arxiv.org/pdf/2106.01223.pdf <br>
https://github.com/yhcc/BARTNER <br>
(以下四篇是基于prompt的命名实体识别) <br>
- Template-Based Named Entity Recognition Using BART <br>
https://arxiv.org/abs/2106.01760 <br>
https://github.com/Nealcly/templateNER <br>
- Good Examples Make A Faster Learner: Simple Demonstration-based Learning for Low-resource NER <br>
https://arxiv.org/abs/2110.08454 <br>
https://github.com/INK-USC/fewNER <br>
- LightNER: A Lightweight Generative Framework with Prompt-guided Attention for Low-resource NER <br>
https://arxiv.org/abs/2109.00720 <br>
https://github.com/zjunlp/DeepKE/blob/main/example/ner/few-shot/README_CN.md <br>
- Template-free Prompt Tuning for Few-shot NER <br>
https://arxiv.org/abs/2109.13532 <br>
https://github.com/rtmaww/EntLM/ <br>


# 数据集

- [MSRA](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/MSRA)
- [Weibo](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/weibo)
- [resume](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/ResumeNER )
- onenotes4
- onenotes5
- [一家公司提供的数据集,包含人名、地名、机构名、专有名词。](https://bosonnlp.com/dev/resource)
- [人民网（04年）](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/people_daily)
- [影视-音乐-书籍实体标注数据](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/video_music_book_datasets)
- [中文医学文本命名实体识别 2020CCKS](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/2020_ccks_ner)
- [医渡云实体识别数据集](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/yidu-s4k )
- [CLUENER2020](https://github.com/GuocaiL/nlp_corpus/tree/main/open_ner_data/cluener_public)
- [不同任务中文数据集整理](https://github.com/liucongg/NLPDataSet)
- [医疗相关的数据集](http://172.16.1.113:9005/docs)
- [30+ner数据汇总](https://zhuanlan.zhihu.com/p/603850842)
- [中文实体识别数据集汇总](https://www.zhihu.com/question/264243637/answer/2936822902)

# 预训练语言模型

- [ChineseBert](https://aclanthology.org/2021.acl-long.161/) ACL2021
- [MacBert](https://arxiv.org/pdf/2004.13922.pdf) 2020
- [SpanBert](https://arxiv.org/pdf/1907.10529.pdf)
- [XLNet](https://arxiv.org/pdf/1906.08237.pdf)
- [Roberta](https://arxiv.org/pdf/1907.11692.pdf)
- [Bert](https://arxiv.org/pdf/1810.04805.pdf)
- [StructBert](https://arxiv.org/abs/1908.04577)
- [WoBert](https://github.com/ZhuiyiTechnology/WoBERT)
- [ELECTRA](https://openreview.net/pdf?id=r1xMH1BtvB)
- [Ernie1.0](https://arxiv.org/pdf/1904.09223)
- [Ernie2.0](https://arxiv.org/abs/1907.12412)
- [Ernie3.0](https://arxiv.org/abs/2107.02137)
- [ERNIE-Gram: Pre-Training with Explicitly N-Gram Masked Language Modeling for Natural Language Understanding](https://arxiv.org/pdf/2010.12148.pdf)
- [NeZha](https://arxiv.org/abs/1909.00204)
- [MengZi](https://arxiv.org/pdf/2110.06696.pdf )
- [ZEN](https://arxiv.org/pdf/1911.00720.pdf)
- [ALBERT](https://arxiv.org/pdf/1909.11942.pdf)
- [roformer](https://arxiv.org/abs/2104.09864)
- [roformer-v2](https://github.com/ZhuiyiTechnology/roformer-v2)
- [Pretraining without Wordpieces: Learning Over a Vocabulary of Millions of Words](https://arxiv.org/pdf/2202.12142)
- [PERT: Pre-Training BERT with Permuted Language Model](https://arxiv.org/abs/2203.06906)
- [RoChBert: Towards Robust BERT Fine-tuning for Chinese](https://arxiv.org/pdf/2210.15944.pdf) EMNLP2022
- [MarkBERT: Marking Word Boundaries Improves Chinese BERT](https://arxiv.org/pdf/2203.06378.pdf) 2022
- [MVP-BERT: REDESIGNING VOCABULARIES FOR CHINESE BERT AND MULTI-VOCAB PRETRAINING](https://arxiv.org/pdf/2011.08539.pdf) 2022
- [LERT: A Linguistically-motivated Pre-trained Language Model](https://arxiv.org/pdf/2211.05344v1.pdf) 2022
- [AMBERT: A Pre-trained Language Model with Multi-Grained Tokenization](https://arxiv.org/pdf/2008.11869.pdf) 2022
- [BURT: BERT-inspired Universal Representation from Learning Meaningful Segment](https://arxiv.org/pdf/2012.14320.pdf) 2021
- [Towards Efficient NLP: A Standard Evaluation and A Strong Baseline](https://aclanthology.org/2022.naacl-main.240.pdf)
- [Fengshenbang 1.0: Being the Foundation of Chinese Cognitive Intelligence](https://arxiv.org/pdf/2209.02970.pdf)
- [AdaSeq: An All-in-One Library for Developing State-of-the-Art Sequence Understanding Models](https://github.com/modelscope/AdaSeq) 多种方法
- [TaCL: Improving BERT Pre-training with Token-aware Contrastive Learning](https://arxiv.org/pdf/2111.04198.pdf) NAACL 2022
- [Character, Word, or Both? Revisiting the Segmentation Granularity for Chinese Pre-trained Language Models](https://arxiv.org/ftp/arxiv/papers/2303/2303.10893.pdf) 2023
- [MiniRBT: A Two-stage Distilled Small Chinese Pre-trained Model](https://arxiv.org/pdf/2304.00717v1.pdf) 2023
- [sikuGPT](https://github.com/SIKU-BERT/sikuGPT) 古文模型 2023
- [UniIE](https://github.com/AAIG-NLP/UniIE) 通用信息抽取
 
# Ner工具

- [Stanza](https://github.com/stanfordnlp/stanza)
- [LAC](https://github.com/baidu/lac)
- [Ltp](https://github.com/HIT-SCIR/ltp) 哈工大
- [Hanlp](https://github.com/hankcs/HanLP)
- [foolnltk](https://github.com/rockyzhengwu/FoolNLTK)
- [NLTK](https://github.com/nltk/nltk)
- BosonNLP
- [FudanNlp](https://github.com/FudanNLP/fnlp) 复旦大学
- [Jionlp](https://github.com/dongrixinyu/JioNLP)
- [HarvestText](https://github.com/blmoistawinde/HarvestText)
- [fastHan](https://github.com/fastnlp/fastHan)
- [EsayNLP](https://github.com/alibaba/EasyNLP) 阿里巴巴
- [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) 百度
- [AliceMind](https://github.com/alibaba/AliceMind) 阿里巴巴
- [spacy](https://github.com/explosion/spaCy)
- [DeepKE](https://github.com/zjunlp/DeepKE)
- [coreNlp](https://github.com/stanfordnlp/CoreNLP) JAVA/Python
- [opennlp](https://github.com/apache/opennlp) JAVA
- [NLPIR](https://github.com/NLPIR-team/NLPIR/)
- [trankit](https://github.com/nlp-uoregon/trankit) 多语言
- [HugIE](https://github.com/wjn1996/HugNLP/blob/main/documents/information_extraction/HugIE.md) 通用信息抽取
- [EasyInstruct](https://github.com/zjunlp/EasyInstruct)

# 比赛

- CCKS2017开放的中文的电子病例测评相关的数据。<br>
评测任务一：https://biendata.com/competition/CCKS2017_1/<br>
评测任务二：https://biendata.com/competition/CCKS2017_2/<br>
- CCKS2018开放的音乐领域的实体识别任务。<br>
评测任务：https://biendata.com/competition/CCKS2018_2/<br>
- (CoNLL 2002)Annotated Corpus for Named Entity Recognition。<br>
地址：https://www.kaggle.com/abhinavwalia95/entity-annotated-corpus<br>
- NLPCC2018开放的任务型对话系统中的口语理解评测。<br>
地址：http://tcci.ccf.org.cn/conference/2018/taskdata.php<br>
- 非结构化商业文本信息中隐私信息识别<br>
地址：https://www.datafountain.cn/competitions/472/datasets
- 商品标题识别<br>
地址：https://www.heywhale.com/home/competition/620b34ed28270b0017b823ad/content/3
- CCKS2021中文NLP地址要素解析<br>
地址：https://tianchi.aliyun.com/competition/entrance/531900/introduction
- CAIL2022信息抽取赛道<br>
地址：http://cail.cipsc.org.cn/task6.html?raceID=6&cail_tag=2022
- [2019互联网金融新实体发现](https://github.com/TingFree/NLPer-Arsenal/blob/master/%E5%BE%80%E6%9C%9F%E7%AB%9E%E8%B5%9B/%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/2019%E4%BA%92%E8%81%94%E7%BD%91%E9%87%91%E8%9E%8D%E6%96%B0%E5%AE%9E%E4%BD%93%E5%8F%91%E7%8E%B0.md) <br> 
- [2020CHIP-中药说明书实体识别挑战](https://github.com/TingFree/NLPer-Arsenal/blob/master/%E5%BE%80%E6%9C%9F%E7%AB%9E%E8%B5%9B/%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/2020%E4%B8%AD%E8%8D%AF%E8%AF%B4%E6%98%8E%E4%B9%A6%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB%E6%8C%91%E6%88%98.md) <br> 
- [2020CHIP-中文医学文本命名实体识别](https://github.com/TingFree/NLPer-Arsenal/blob/master/%E5%BE%80%E6%9C%9F%E7%AB%9E%E8%B5%9B/%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/2020%E4%B8%AD%E6%96%87%E5%8C%BB%E5%AD%A6%E6%96%87%E6%9C%AC%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.md) <br> 
- [2020CCKS面向试验鉴定的命名实体识别](https://github.com/TingFree/NLPer-Arsenal/blob/master/%E5%BE%80%E6%9C%9F%E7%AB%9E%E8%B5%9B/%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/2020CCKS%E9%9D%A2%E5%90%91%E8%AF%95%E9%AA%8C%E9%89%B4%E5%AE%9A%E7%9A%84%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.md) <br> 
- [2020CCKS面向中文电子病历的医疗实体及事件抽取-子任务1：医疗命名实体识别](https://github.com/TingFree/NLPer-Arsenal/blob/master/%E5%BE%80%E6%9C%9F%E7%AB%9E%E8%B5%9B/%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB/2020CCKS%E9%9D%A2%E5%90%91%E4%B8%AD%E6%96%87%E7%94%B5%E5%AD%90%E7%97%85%E5%8E%86%E7%9A%84%E5%8C%BB%E7%96%97%E5%AE%9E%E4%BD%93%E5%8F%8A%E4%BA%8B%E4%BB%B6%E6%8A%BD%E5%8F%96-%E5%AD%90%E4%BB%BB%E5%8A%A1%E4%B8%80%EF%BC%9A%E5%8C%BB%E7%96%97%E5%90%8D%E9%97%A8%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB.md) 
- [LAIC2022-犯罪事实实体识别](http://data.court.gov.cn/pages/laic.html)
- [SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition (MultiCoNER 2)](https://arxiv.org/pdf/2305.06586v1.pdf)
- [新型电力系统人工智能应用大赛赛题二：电力生产知识图谱多模式信息抽取](https://aistudio.baidu.com/aistudio/competition/detail/425/0/task-definition)
- [CCKS2022通用信息抽取](https://aistudio.baidu.com/aistudio/competition/detail/161/0/introduction)
