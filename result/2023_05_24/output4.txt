参数：
MLP：1500*256*3
lr = 1e-3  # 学习率
batch_size = 500  # batch
epoch = 10000  # 训练次数
val_time = 500  # 每训练多少次验证一次
weight = 0.05
删除0.9的全O

基本信息统计：
训练集大小:481408 验证集大小：112189 测试集大小：223834
-------------train-------------
0/10000
loss=120055.5859375
hit=189 p_sum=14078 r_sum=4532
precision=0.01342520244352891 recall=0.04170344218887908
f1-measure=0.02031166039763568

500/10000
loss=116520.4921875
hit=2465 p_sum=61460 r_sum=4532
precision=0.04010738691832086 recall=0.543909973521624
f1-measure=0.07470602497272397

1000/10000
loss=115427.078125
hit=2814 p_sum=42734 r_sum=4532
precision=0.06584920672064398 recall=0.6209179170344219
f1-measure=0.1190707908433123

1500/10000
loss=111418.515625
hit=3411 p_sum=45160 r_sum=4532
precision=0.07553144375553587 recall=0.7526478375992939
f1-measure=0.13728567978749093

2000/10000
loss=100940.734375
hit=3556 p_sum=38820 r_sum=4532
precision=0.091602266872746 recall=0.7846425419240953
f1-measure=0.16405240819339362

2500/10000
loss=96120.9921875
hit=3676 p_sum=33570 r_sum=4532
precision=0.10950253202263927 recall=0.8111209179170344
f1-measure=0.19295575035431212

3000/10000
loss=92614.03125
hit=3800 p_sum=32097 r_sum=4532
precision=0.1183911268965947 recall=0.8384819064430715
f1-measure=0.20748587185017336

3500/10000
loss=89272.3828125
hit=3821 p_sum=28247 r_sum=4532
precision=0.13527100223032534 recall=0.8431156222418358
f1-measure=0.2331370694652064

4000/10000
loss=91572.53125
hit=3965 p_sum=32157 r_sum=4532
precision=0.12330130298224337 recall=0.8748896734333628
f1-measure=0.2161410777072147

4500/10000
loss=86920.71875
hit=3947 p_sum=27551 r_sum=4532
precision=0.143261587601176 recall=0.8709179170344219
f1-measure=0.24604930960321664

5000/10000
loss=84256.8671875
hit=3920 p_sum=25563 r_sum=4532
precision=0.1533466338066737 recall=0.8649602824360106
f1-measure=0.26050839009802296

5500/10000
loss=88407.6015625
hit=4044 p_sum=30459 r_sum=4532
precision=0.13276863981089332 recall=0.8923212709620476
f1-measure=0.23114515161041407

6000/10000
loss=81323.390625
hit=3925 p_sum=23628 r_sum=4532
precision=0.16611647198239377 recall=0.8660635481023831
f1-measure=0.27876420454545453

6500/10000
loss=84143.2109375
hit=4006 p_sum=26495 r_sum=4532
precision=0.15119833930930365 recall=0.8839364518976169
f1-measure=0.25822670577239176

7000/10000
loss=82009.8671875
hit=3982 p_sum=24665 r_sum=4532
precision=0.16144334076626798 recall=0.8786407766990292
f1-measure=0.27276775011131277

7500/10000
loss=84001.015625
hit=4040 p_sum=26871 r_sum=4532
precision=0.15034795876595586 recall=0.8914386584289496
f1-measure=0.2573002579371398

8000/10000
loss=80383.8828125
hit=3974 p_sum=22927 r_sum=4532
precision=0.1733327517773804 recall=0.8768755516328332
f1-measure=0.28944972504461197

8500/10000
loss=81332.5625
hit=4016 p_sum=24319 r_sum=4532
precision=0.16513836917636415 recall=0.8861429832303619
f1-measure=0.2783958961561125

9000/10000
loss=80809.4140625
hit=4034 p_sum=24468 r_sum=4532
precision=0.16486839954225926 recall=0.8901147396293028
f1-measure=0.2782068965517241

9500/10000
loss=78727.09375
hit=3987 p_sum=21691 r_sum=4532
precision=0.18380895302199068 recall=0.8797440423654016
f1-measure=0.3040842008923464

10000/10000
loss=80813.75
hit=4039 p_sum=24571 r_sum=4532
precision=0.1643807740832689 recall=0.8912180052956752
f1-measure=0.27756588667834936


-------------test-------------

loss=161490.640625
hit=7704 p_sum=49084 r_sum=8606
precision=0.15695542335587973 recall=0.8951894027422729
f1-measure=0.2670826833073323
