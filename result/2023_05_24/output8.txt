参数：
MLP：1500*256*3
lr = 1e-3  # 学习率
batch_size = 500  # batch
epoch = 10000  # 训练次数
val_time = 500  # 每训练多少次验证一次
weight = 0.175
删除0.9的全O



基本信息统计：
训练集大小:481408 验证集大小：112189 测试集大小：223834
-------------train-------------
0/10000
loss=120387.4375
hit=1298 p_sum=52630 r_sum=4532
precision=0.024662739882196465 recall=0.28640776699029125
f1-measure=0.04541478604667436

500/10000
loss=66550.3125
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

1000/10000
loss=65773.5703125
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

1500/10000
loss=65566.953125
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

2000/10000
loss=65468.9375
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

2500/10000
loss=65461.66796875
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

3000/10000
loss=65482.27734375
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

3500/10000
loss=65662.7734375
hit=0 p_sum=0 r_sum=4532
precision=0 recall=0.0
f1-measure=0

4000/10000
loss=67156.8984375
hit=358 p_sum=511 r_sum=4532
precision=0.700587084148728 recall=0.07899382171226832
f1-measure=0.14197898076541743

4500/10000
loss=67994.15625
hit=687 p_sum=1454 r_sum=4532
precision=0.47248968363136173 recall=0.15158870255957635
f1-measure=0.22953558302706317

5000/10000
loss=68905.3515625
hit=773 p_sum=2513 r_sum=4532
precision=0.30760047751691205 recall=0.1705648720211827
f1-measure=0.21944641589779984

5500/10000
loss=70600.65625
hit=987 p_sum=3449 r_sum=4532
precision=0.28616990432009276 recall=0.2177846425419241
f1-measure=0.24733742638767073

6000/10000
loss=72934.4765625
hit=1561 p_sum=5337 r_sum=4532
precision=0.29248641558928234 recall=0.3444395410414828
f1-measure=0.3163441078123417

6500/10000
loss=71914.34375
hit=2126 p_sum=6504 r_sum=4532
precision=0.3268757687576876 recall=0.46910856134157103
f1-measure=0.38528452337803554

7000/10000
loss=69515.1796875
hit=2383 p_sum=6272 r_sum=4532
precision=0.3799426020408163 recall=0.5258164165931156
f1-measure=0.44113291373565344

7500/10000
loss=69713.3671875
hit=2695 p_sum=7304 r_sum=4532
precision=0.3689759036144578 recall=0.5946601941747572
f1-measure=0.4553903345724907

8000/10000
loss=69928.796875
hit=2899 p_sum=8203 r_sum=4532
precision=0.35340729001584786 recall=0.6396734333627537
f1-measure=0.45528072241853157

8500/10000
loss=68226.75
hit=2867 p_sum=6867 r_sum=4532
precision=0.41750400465996795 recall=0.6326125330979699
f1-measure=0.5030265812790595

9000/10000
loss=69428.8671875
hit=3085 p_sum=8639 r_sum=4532
precision=0.35710151637921056 recall=0.6807149161518093
f1-measure=0.46845342039328824

9500/10000
loss=68852.546875
hit=3105 p_sum=7991 r_sum=4532
precision=0.3885621323989488 recall=0.6851279788172993
f1-measure=0.4958875668769464

10000/10000
loss=67642.0546875
hit=3048 p_sum=7259 r_sum=4532
precision=0.41989254718280755 recall=0.6725507502206531
f1-measure=0.5170044949537783


-------------test-------------

loss=134715.609375
hit=5645 p_sum=14006 r_sum=8606
precision=0.4030415536198772 recall=0.6559377178712527
f1-measure=0.4992924111091456
